{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import desire.utils.data_loader as dl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# execfile(\"utils/data_loader.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "509\n",
      "509\n",
      "509\n",
      "509\n",
      "14558\n"
     ]
    }
   ],
   "source": [
    "seq_length = 20\n",
    "batch_size = 1\n",
    "max_num_obj = 60\n",
    "\n",
    "data_loader = dl.DataLoader(max_num_obj, seq_length, max_num_obj, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_loader.reset_batch_pointer()\n",
    "# print(np.asarray(xval).shape)\n",
    "# xval = np.asarray(xval)\n",
    "# yval = np.asarray(yval)\n",
    "# # vals = np.hstack([xval, yval])\n",
    "# print(xval.shape)\n",
    "# a = vals[:, :, 5, 1:]\n",
    "# # print(a.reshape(:, 16*2).shape)\n",
    "# print(\"-----\")\n",
    "# # print(np.asarray(vals[0, :, 1, :]).shape)\n",
    "# print(xval[0, :, 1, :])\n",
    "# a = np.asarray([[xval[y, :, i, 1:] for i in range(max_num_obj)] for y in range(batch_size)])\n",
    "# print(np.asarray(a).shape)\n",
    "# # a = a.reshape([batch_size*max_num_obj, seq_length*2])\n",
    "# print(a.shape)\n",
    "# # print(a[0, 1, :])\n",
    "# # a = a.reshape([1, 2*seq_length])\n",
    "# # print(a.shape)\n",
    "# # print(a.reshape([seq_length, 2]))\n",
    "# # print(yval[0, :, 2, 1:])\n",
    "\n",
    "# tar = xval - 1\n",
    "# print(np.mean(xval[0, :, 2, 1:] - tar[0, :, 2, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xval = np.asarray(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 954.   954.   954.   956.5  956.5  959.   959.   959.   962.   962.   965.\n",
      "  965.   966.   967.5  967.5  970.   970.   973.   973.   973. ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEUFlICIiqAxERAT4/1q487CTok1BAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff30f92d9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.figure()\n",
    "# print(xval[0, :, 1, 1])\n",
    "# plt.plot(xval[0, :, 4, 2], xval[0, :, 4, 1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coef(output):\n",
    "    # eq 20 -> 22 of Graves (2013)\n",
    "\n",
    "    z = output\n",
    "    # Split the output into 5 parts corresponding to means, std devs and corr\n",
    "    z_mux, z_muy, z_sx, z_sy, z_corr = tf.split(z, 5, 1)\n",
    "\n",
    "    # The output must be exponentiated for the std devs\n",
    "    z_sx = tf.exp(z_sx)\n",
    "    z_sy = tf.exp(z_sy)\n",
    "    # Tanh applied to keep it in the range [-1, 1]\n",
    "    z_corr = tf.tanh(z_corr)\n",
    "\n",
    "    return [z_mux, z_muy, z_sx, z_sy, z_corr]\n",
    "\n",
    "def get_lossfunc(z_mux, z_muy, z_sx, z_sy, z_corr, x_data, y_data):\n",
    "    '''\n",
    "    Function to calculate given a 2D distribution over x and y, and target data\n",
    "    of observed x and y points\n",
    "    params:\n",
    "    z_mux : mean of the distribution in x\n",
    "    z_muy : mean of the distribution in y\n",
    "    z_sx : std dev of the distribution in x\n",
    "    z_sy : std dev of the distribution in y\n",
    "    z_rho : Correlation factor of the distribution\n",
    "    x_data : target x points\n",
    "    y_data : target y points\n",
    "    '''\n",
    "\n",
    "    # Calculate the PDF of the data w.r.t to the distribution\n",
    "    result0 = tf_2d_normal(x_data, y_data, z_mux, z_muy, z_sx, z_sy, z_corr)\n",
    "    # For numerical stability purposes\n",
    "    epsilon = 1e-20\n",
    "\n",
    "    # Apply the log operation\n",
    "    result1 = -tf.log(tf.maximum(result0, epsilon))  # Numerical stability\n",
    "\n",
    "    # Sum up all log probabilities for each data point\n",
    "    return tf.reduce_sum(result1)\n",
    "\n",
    "def tf_2d_normal(x, y, mux, muy, sx, sy, rho):\n",
    "    '''\n",
    "    Function that implements the PDF of a 2D normal distribution\n",
    "    params:\n",
    "    x : input x points\n",
    "    y : input y points\n",
    "    mux : mean of the distribution in x\n",
    "    muy : mean of the distribution in y\n",
    "    sx : std dev of the distribution in x\n",
    "    sy : std dev of the distribution in y\n",
    "    rho : Correlation factor of the distribution\n",
    "    '''\n",
    "    # eq 3 in the paper\n",
    "    # and eq 24 & 25 in Graves (2013)\n",
    "    # Calculate (x - mux) and (y-muy)\n",
    "    normx = tf.subtract(x, mux)\n",
    "    normy = tf.subtract(y, muy)\n",
    "    # Calculate sx*sy\n",
    "    sxsy = tf.multiply(sx, sy)\n",
    "    # Calculate the exponential factor\n",
    "    z = tf.square(tf.div(normx, sx)) + tf.square(tf.div(normy, sy)) - 2*tf.div(tf.multiply(rho, tf.multiply(normx, normy)), sxsy)\n",
    "    negRho = 1 - tf.square(rho)\n",
    "    # Numerator\n",
    "    result = tf.exp(tf.div(-z, 2*negRho))\n",
    "    # Normalization constant\n",
    "    denom = 2 * np.pi * tf.multiply(sxsy, tf.sqrt(negRho))\n",
    "    # Final PDF calculation\n",
    "    result = tf.div(result, denom)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Size of the encoding layer (the hidden layer)\n",
    "encoding_dim = 8 # feel free to change this value\n",
    "\n",
    "input_size = 3\n",
    "\n",
    "grad_clip = 10.0\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Input and target placeholders\n",
    "inputs = tf.placeholder(tf.float32, (seq_length, max_num_obj, input_size), name=\"inputs\")\n",
    "\n",
    "nonexistent_ped = tf.constant(0.0, name=\"zero_ped\")\n",
    "# inputs = tf.reshape(inputs_, shape=[-1, input_size])\n",
    "targets = tf.placeholder(tf.float32, (seq_length, max_num_obj, input_size), name=\"targets\")\n",
    "# targets = tf.reshape(targets_, shape=[-1, input_size])\n",
    "lr = tf.Variable(learning_rate, trainable=False, name=\"learning_rate\")\n",
    "frame_target_data = [tf.squeeze(target_, [0]) for target_ in tf.split(targets, seq_length, 0)]\n",
    "\n",
    "cost = tf.constant(0.0, name=\"cost\")\n",
    "counter = tf.constant(0.0, name=\"counter\")\n",
    "increment = tf.constant(1.0, name=\"increment\")\n",
    "\n",
    "# frame_data = tf.split(0, args.seq_length, self.input_data, name=\"frame_data\")\n",
    "frame_data = [tf.squeeze(input_, [0]) for input_ in tf.split(inputs, seq_length, 0)]\n",
    "\n",
    "for seq, frame in enumerate(frame_data):\n",
    "# Output of hidden layer, single fully connected layer here with ReLU activation\n",
    "    current_frame = frame\n",
    "    for ped in range(max_num_obj):\n",
    "        pedID = current_frame[ped, 0]\n",
    "        spat_input = tf.slice(current_frame, [ped, 1], [1, 2])\n",
    "        encoded = tf.layers.dense(spat_input, 5, activation=tf.nn.relu)\n",
    "\n",
    "#         # Output layer logits, fully connected layer with no activation\n",
    "#         logits = tf.layers.dense(encoded, input_size, activation=None)\n",
    "#         # Sigmoid output from logits\n",
    "#         decoded = tf.sigmoid(logits, name = \"decoded\")\n",
    "        [x_data, y_data] = tf.split(tf.slice(frame_target_data[seq], [ped, 1], [1, 2]), 2, 1)\n",
    "        target_pedID = frame_target_data[seq][ped, 0]\n",
    "        [o_mux, o_muy, o_sx, o_sy, o_corr] = get_coef(encoded)\n",
    "        lossfunc = get_lossfunc(o_mux, o_muy, o_sx, o_sy, o_corr, x_data, y_data)\n",
    "        # If it is a non-existent ped, it should not contribute to cost\n",
    "        # If the ped doesn't exist in the next frame, he/she should not contribute to cost as well\n",
    "        cost = tf.where(tf.logical_or(tf.equal(pedID, nonexistent_ped), tf.equal(target_pedID, nonexistent_ped)), cost, tf.add(cost, lossfunc))\n",
    "        counter = tf.where(tf.logical_or(tf.equal(pedID, nonexistent_ped), tf.equal(target_pedID, nonexistent_ped)), counter, tf.add(counter, increment))\n",
    "\n",
    "cost = tf.div(cost, counter)\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "gradients = tf.gradients(cost, tvars)\n",
    "\n",
    "grads, _ = tf.clip_by_global_norm(gradients, grad_clip)\n",
    "# Adam optimizer\n",
    "# Define the optimizer\n",
    "optimizer = tf.train.RMSPropOptimizer(lr)\n",
    "\n",
    "# The train operator\n",
    "train_op = optimizer.apply_gradients(zip(grads, tvars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/480 (epoch 0), train_loss = nan, time/batch = 18.196\n",
      "1/480 (epoch 0), train_loss = nan, time/batch = 1.471\n",
      "2/480 (epoch 0), train_loss = nan, time/batch = 1.565\n",
      "3/480 (epoch 0), train_loss = nan, time/batch = 1.509\n",
      "4/480 (epoch 0), train_loss = nan, time/batch = 1.411\n",
      "5/480 (epoch 0), train_loss = nan, time/batch = 1.413\n",
      "6/480 (epoch 0), train_loss = nan, time/batch = 1.403\n",
      "7/480 (epoch 0), train_loss = nan, time/batch = 1.429\n",
      "8/480 (epoch 0), train_loss = nan, time/batch = 1.439\n",
      "9/480 (epoch 0), train_loss = nan, time/batch = 1.477\n",
      "10/480 (epoch 0), train_loss = nan, time/batch = 1.466\n",
      "11/480 (epoch 0), train_loss = nan, time/batch = 1.487\n",
      "12/480 (epoch 0), train_loss = nan, time/batch = 1.515\n",
      "13/480 (epoch 0), train_loss = nan, time/batch = 1.497\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-94d56e54d175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#             print(xval.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxval\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mloss_batch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/todor/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/todor/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/todor/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/todor/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/todor/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 10\n",
    "loss = 0\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    for ii in range(data_loader.num_batches):\n",
    "        start = time.time()\n",
    "        x, y, d = data_loader.next_batch()\n",
    "        loss_batch = 0\n",
    "        for batch in range(batch_size):\n",
    "            xval = x[batch]\n",
    "#             xval = np.swapaxes(xval, 0, 1)\n",
    "#             print(xval.shape)\n",
    "            feed = {inputs: xval, targets: xval}\n",
    "            train_loss, _ = sess.run([cost, train_op], feed)\n",
    "\n",
    "            loss_batch += train_loss\n",
    "        end = time.time()\n",
    "        loss_batch = loss_batch / batch_size\n",
    "        loss += loss_batch\n",
    "        print(\n",
    "            \"{}/{} (epoch {}), train_loss = {:.3f}, time/batch = {:.3f}\"\n",
    "            .format(\n",
    "                e * data_loader.num_batches + ii,\n",
    "                epochs * data_loader.num_batches,\n",
    "                e,\n",
    "                loss_batch, end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Size of the encoding layer (the hidden layer)\n",
    "encoding_dim = 32 # feel free to change this value\n",
    "\n",
    "image_size = mnist.train.images.shape[1]\n",
    "\n",
    "# Input and target placeholders\n",
    "inputs_ = tf.placeholder(tf.float32, (None, image_size), name=\"inputs\")\n",
    "targets_ = tf.placeholder(tf.float32, (None, image_size), name=\"targets\")\n",
    "\n",
    "# Output of hidden layer, single fully connected layer here with ReLU activation\n",
    "encoded = tf.layers.dense(inputs_, 32, activation=tf.nn.relu)\n",
    "\n",
    "# Output layer logits, fully connected layer with no activation\n",
    "logits = tf.layers.dense(encoded, image_size, activation=None)\n",
    "# Sigmoid output from logits\n",
    "decoded = tf.sigmoid(logits, name = \"decoded\")\n",
    "\n",
    "# Sigmoid cross-entropy loss\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=targets_)\n",
    "# Mean of the loss\n",
    "cost = tf.reduce_mean(loss)\n",
    "\n",
    "# Adam optimizer\n",
    "opt = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
